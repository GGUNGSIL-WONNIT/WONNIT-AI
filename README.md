ğŸ” Change Detection & ğŸ§­ Space Item Detection & ğŸ§ª Space Classification
(TinyChangeUNet Â· YOLOv8 Â· PyTorch/timm)
<p align="center"> <img src="https://img.shields.io/badge/python-3.10%2B-1f6feb"> <img src="https://img.shields.io/badge/pytorch-2.x-EE4C2C"> <img src="https://img.shields.io/badge/timm-MobileNetV3-ffc107"> <img src="https://img.shields.io/badge/ultralytics-YOLOv8-00b894"> <img src="https://img.shields.io/badge/repro-seed%3D42-8957e5"> </p>

ë³¸ ì €ì¥ì†ŒëŠ” ì‹¤ë‚´ ê³µê°„ ë°ì´í„°ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•˜ëŠ” ì„¸ ê°€ì§€ ì‘ì—…ì„ í¬í•¨í•©ë‹ˆë‹¤.
Change Detection â€” YOLO ë¼ë²¨ ë°•ìŠ¤ë¡œ í•©ì„±í•œ before/after ìŒ + ë³€ê²½ GT(0/255) ìƒì„±, ê²½ëŸ‰ TinyChangeUNet(MobileNetV3 encoder) í•™ìŠµ/í‰ê°€
Space Item Detection â€” ì‹¤ë‚´ ì‚¬ì§„ì—ì„œ ì—ì–´ì»¨/ê±°ìš¸/í”¼ì•„ë…¸ ë“± YOLOv8 íƒì§€
Space Classification â€” ê³µê°„/ë¬¼í’ˆì˜ ë‹¨ì¼ ì´ë¯¸ì§€ ë¶„ë¥˜(PyTorch/timm ê¸°ë°˜, ìŠ¤í¬ë¦½íŠ¸: space_classification.py)

ëª©ì°¨
í™˜ê²½ ì¤€ë¹„
í´ë” êµ¬ì¡°
ëª¨ë“ˆ A â€” Change Detection
ëª¨ë“ˆ B â€” Space Item Detection
ëª¨ë“ˆ C â€” Space Classification
ì¬í˜„ì„± & ë¼ì´ì„ ìŠ¤
ë¬¸ì˜
í™˜ê²½ ì¤€ë¹„

# ê³µí†µ ì˜ì¡´ì„± (ë¡œì»¬/ì½œë© ê³µí†µ)
pip install torch torchvision timm ultralytics opencv-python numpy matplotlib tqdm scikit-learn
ë…¸íŠ¸ë¶ íŒŒì¼: change_detection.ipynb, space_item_detection.ipynb
ë¶„ë¥˜ ìŠ¤í¬ë¦½íŠ¸: space_classification.py
í´ë” êµ¬ì¡°
# A) Change Detection (í•©ì„± ë°ì´í„°)
pairs_out_cd/
  train/{before_images, after_images, labels}
  val/{before_images, after_images, labels}
  test/{before_images, after_images, labels}
meta/pairs_{train,val}.json

# B) Space Item Detection (YOLO í˜•ì‹)
space_data/
  images/{train,val,test}/*.jpg|png
  labels/{train,val,test}/*.txt        # YOLO txt (cls cx cy w h)
  space.yaml                           # ë°ì´í„° êµ¬ì„±/í´ë˜ìŠ¤ ì •ì˜

# C) Space Classification (í´ë˜ìŠ¤ë³„ í´ë” êµ¬ì¡°)
space_cls/
  train/<class_name>/*.jpg|png
  val/<class_name>/*.jpg|png
  test/<class_name>/*.jpg|png
ë§ˆìŠ¤í¬ëŠ” 0/255 ë°”ì´ë„ˆë¦¬ PNG (ë¦¬ì‚¬ì´ì¦ˆ ì‹œ nearest ê¶Œì¥).
YOLO ë¼ë²¨ì€ cls cx cy w h ì •ê·œí™” í˜•ì‹.
ëª¨ë“ˆ A â€” Change Detection
ë…¸íŠ¸ë¶: change_detection.ipynb
ëª¨ë¸: TinyChangeUNet (MobileNetV3 Small encoder)
ì…ë ¥: before(3)Â·after(3)Â·diff(1) â†’ 7ì±„ë„
âœ¨ í•µì‹¬
í•©ì„± ë°ì´í„° êµ¬ì¶•: ê°€ë¦¼/ë¸”ëŸ¬/í”½ì…€í™”/ì¸í˜ì¸íŠ¸/ì´ë™ìœ¼ë¡œ after + GT(0/255) ìƒì„±
ëª¨ë¸: 7ch â†’ 1Ã—1 conv ì¶•ì†Œ â†’ MobileNetV3 encoder â†’ ê²½ëŸ‰ decoder â†’ 1ch logit
í•™ìŠµ ë£¨í”„: AMP(FP16), Cosine+Warmup, EMA ê²€ì¦/ì €ì¥, pos_weight ìë™ ì¶”ì •
í‰ê°€: ê²€ì¦ threshold sweepìœ¼ë¡œ ìµœì  th â†’ í…ŒìŠ¤íŠ¸ mIoU/F1 + PNG ì €ì¥
flowchart LR
    A[Before (3ch)] ---|concat| R[Reduce 1x1 Conv â†’ 3ch]
    B[After (3ch)]  ---|concat| R
    D[abs(Before-After) (1ch)] ---|concat| R
    R --> E[MobileNetV3 Encoder]
    E -->|multi-scale| Dec[Tiny Decoder]
    Dec --> H[Head 1x1 Conv]
    H --> M[Logit â†’ Sigmoid â†’ Binary Mask (0/255)]
í€µìŠ¤íƒ€íŠ¸
PairDataset2In ì •ì˜ â†’ 2) TinyChangeUNet ì •ì˜ â†’ 3) Train/Eval ë£¨í”„ ì‹¤í–‰(IMG_SIZE=256, BATCH=8, LR=3e-4, EPOCHS=40) â†’ 4) Self-contained TEST Evalë¡œ ì¬ì‹œì‘ í›„ í‰ê°€
ê²°ê³¼ ì¹´ë“œ(ì˜ˆì‹œ)
Split	Best-th	mIoU	F1	AMP	EMA
Val	0.18	0.41	0.51	âœ…	âœ…
Test	0.18	0.40	0.50	âœ…	âœ…
ëª¨ë“ˆ B â€” Space Item Detection
ë…¸íŠ¸ë¶: space_item_detection.ipynb
ëª¨ë¸: YOLOv8 (COCO ì‚¬ì „í•™ìŠµ â†’ ì»¤ìŠ¤í…€ í´ë˜ìŠ¤ íŒŒì¸íŠœë‹)
ë°ì´í„° ì„¤ì • (space.yaml ì˜ˆì‹œ)
path: ./space_data
train: images/train
val: images/val
test: images/test

names:
  0: air_conditioner
  1: mirror
  2: piano
  # ...
í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸
from ultralytics import YOLO
model = YOLO("yolov8n.pt")  # n/s/m/l/x ì¤‘ ì„ íƒ
model.train(data="space_data/space.yaml", imgsz=640, epochs=100, batch=16, seed=42)
model.val(data="space_data/space.yaml", imgsz=640, split="val")
model.predict(source="space_data/images/test", imgsz=640, save=True, conf=0.25)
ê²°ê³¼ ì¹´ë“œ(ì˜ˆì‹œ)
Split	mAP@0.5	mAP@0.5:0.95	ì´ë¯¸ì§€í¬ê¸°	ëª¨ë¸
Val	0.xx	0.xx	640	YOLOv8n
Test	0.xx	0.xx	640	YOLOv8n
ëª¨ë“ˆ C â€” Space Classification
ìŠ¤í¬ë¦½íŠ¸: space_classification.py
ëª©ì : ê³µê°„/ë¬¼í’ˆ ì´ë¯¸ì§€ë¥¼ í´ë˜ìŠ¤ ë‹¨ìœ„ë¡œ ë¶„ë¥˜(ì˜ˆ: living_room, study_room, kitchen ë˜ëŠ” air_conditioner, mirror, â€¦)
ë°ì´í„° í¬ë§·
í´ë˜ìŠ¤ë³„ í´ë” êµ¬ì¡°(ì´ë¯¸ ìœ„ â€œí´ë” êµ¬ì¡°â€ ì°¸ê³ ):
space_cls/
  train/<class_name>/*.jpg|png
  val/<class_name>/*.jpg|png
  test/<class_name>/*.jpg|png
ì˜ˆì‹œ ì‹¤í–‰
â€» ìŠ¤í¬ë¦½íŠ¸ ì¸ìëª…ì€ êµ¬í˜„ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. python space_classification.py -h ë¡œ í™•ì¸í•˜ì„¸ìš”.
# í•™ìŠµ
python space_classification.py \
  --data space_cls \
  --img-size 224 \
  --batch-size 32 \
  --epochs 50 \
  --model resnet18 \
  --lr 3e-4 \
  --seed 42 \
  --save ckpt_space_cls.pt

# í‰ê°€(ê°€ì¤‘ì¹˜ ë¡œë“œ í›„ test ì„±ëŠ¥ ë¦¬í¬íŠ¸)
python space_classification.py \
  --data space_cls \
  --img-size 224 \
  --batch-size 32 \
  --weights ckpt_space_cls.pt \
  --eval
ê¶Œì¥ ì‚¬í•­
ì „ì´í•™ìŠµ: timm ì‚¬ì „í•™ìŠµ ë°±ë³¸(resnet/efficientnet/mobilevit ë“±) ì‚¬ìš© ì‹œ ìˆ˜ë ´/ì •í™•ë„ ìœ ë¦¬
í´ë˜ìŠ¤ ë¶ˆê· í˜•: WeightedRandomSampler ë˜ëŠ” class_weight(loss)ì— ë°˜ì˜
ë¡œê¹…: Top-1 Acc, macro F1, Confusion Matrix ì €ì¥
ê²°ê³¼ ì¹´ë“œ(ì˜ˆì‹œ)
Split	Top-1 Acc	Macro F1	ImgSize	Backbone
Val	0.xx	0.xx	224	resnet18
Test	0.xx	0.xx	224	resnet18
<details> <summary><b>Confusion Matrix ì‹œê°í™”(ì˜ˆì‹œ)</b></summary>
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

cm = confusion_matrix(y_true, y_pred, labels=range(len(class_names)))
disp = ConfusionMatrixDisplay(cm, display_labels=class_names)
fig, ax = plt.subplots(figsize=(6,6))
disp.plot(ax=ax, cmap="Blues", colorbar=False, xticks_rotation=45)
plt.tight_layout(); plt.savefig("confusion_matrix.png")
</details>
