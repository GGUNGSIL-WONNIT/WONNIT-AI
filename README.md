# ğŸ·ï¸ Scene Classification Â· ğŸ§­ Space Item Detection Â· ğŸ” Change Detection
MobileNetV2 (torchvision) Â· YOLOv8n Â· TinyChangeUNet (MobileNetV3 encoder)

<p align="center">
  <img src="https://img.shields.io/badge/python-3.10%2B-1f6feb">
  <img src="https://img.shields.io/badge/pytorch-2.x-EE4C2C">
  <img src="https://img.shields.io/badge/classifier-MobileNetV2(torchvision)-4ea1ff">
  <img src="https://img.shields.io/badge/detector-YOLOv8n-00b894">
  <img src="https://img.shields.io/badge/change-TinyChangeUNet(MobileNetV3)-ffd24d">
  <img src="https://img.shields.io/badge/repro-seed%3D42-8957e5">
</p>

<p align="center">
  ì‹¤ë‚´ ê³µê°„ ë°ì´í„°ë¥¼ ëŒ€ìƒìœ¼ë¡œ <b>ì¥ì†Œ ë¶„ë¥˜</b> â†’ <b>ê³µê°„ ì•„ì´í…œ íƒì§€</b> â†’ <b>ë³€í™” ê°ì§€</b>ë¥¼ í•˜ë‚˜ì˜ ê²½ëŸ‰ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì œê³µí•©ë‹ˆë‹¤.
</p>

---

- [í´ë” êµ¬ì¡°](#-í´ë”-êµ¬ì¡°)
- [A) Scene Classification (ì¥ì†Œ ë¶„ë¥˜)](#a-scene-classification-ì¥ì†Œ-ë¶„ë¥˜)
- [B) Space Item Detection (ì•„ì´í…œ íƒì§€)](#b-space-item-detection-ì•„ì´í…œ-íƒì§€)
- [C) Change Detection (ì „í›„ ë³€í™” ê°ì§€)](#c-change-detection-ì „í›„-ë³€í™”-ê°ì§€)
- [ì¬í˜„ì„±](#-ì¬í˜„ì„±)

---

## ğŸ“ í´ë” êµ¬ì¡°

```text
A) Scene Classification (ImageFolder)
space_cls/
  train/<class>/*.jpg|png
  val/<class>/*.jpg|png
  test/<class>/*.jpg|png

B) Space Item Detection (YOLO)
space_data/
  images/{train,val,test}/*.jpg|png
  labels/{train,val,test}/*.txt      # YOLO: cls cx cy w h
  space.yaml

C) Change Detection (í•©ì„± before/after/GT)
pairs_out_cd/
  train/{before_images,after_images,labels}
  val/{before_images,after_images,labels}
  test/{before_images,after_images,labels}
meta/pairs_{train,val}.json
```

---

## A) Scene Classification (ì¥ì†Œ ë¶„ë¥˜)
    
**ëª¨ë¸**: MobileNetV2 *(torchvision, ImageNet ì‚¬ì „í•™ìŠµ â†’ íŒŒì¸íŠœë‹)*  
**ì…ë ¥**: 224Ã—224  
**íƒ€ê¹ƒ í´ë˜ìŠ¤(5)**: `creative_studio`, `dance_studio`, `music_rehearsal_room`, `small_theater_gallery`, `study_room`  
**ë°ì´í„° êµ¬ì¶•**: í´ë˜ìŠ¤ë‹¹ ~50ì¥ *(1ì°¨ í¬ë¡¤ë§ â†’ 2ì°¨ ìˆ˜ì‘ì—… ì •ì œ)* í›„ **train:val=8:2** ë¶„í• , ImageFolder í¬ë§·

```bash
# í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
python train_mobilenet.py
# ì‚°ì¶œë¬¼: mobilenetv2.pth, class_names.txt
```

**í…ŒìŠ¤íŠ¸ ì„±ëŠ¥(í´ë˜ìŠ¤ë³„ ì •í™•ë„)**  
| Class | Correct / Total | Acc. |
|---|---:|---:|
| creative_studio | 10 / 10 | **100.0%** |
| dance_studio | 8 / 10 | **80.0%** |
| music_rehearsal_room | 7 / 10 | **70.0%** |
| small_theater_gallery | 8 / 10 | **80.0%** |
| study_room | 10 / 10 | **100.0%** |

<img width="1290" height="998" alt="matrix" src="https://github.com/user-attachments/assets/31a65d1a-5148-461b-a993-5ef87e921895" />

**Overall Acc**: 43/50 = **86.0%** Â· **Macro Acc**: **86.0%**  
> ì£¼ìš” ì˜¤ë¶„ë¥˜: `dance_studio â†’ small_theater_gallery` 2ê±´, `music_rehearsal_room â†’ study_room` 2ê±´ ë“±.



---
## B) Space Item Detection (ì•„ì´í…œ íƒì§€)

**ëª¨ë¸**: YOLOv8n *(Ultralytics, COCO ì‚¬ì „í•™ìŠµ â†’ ì»¤ìŠ¤í…€ íŒŒì¸íŠœë‹)*  
**ëª©ì **: ì‹¤ë‚´ ì‚¬ì§„ì—ì„œ ê³µê°„ ì•„ì´í…œ(13ì¢…)ì„ íƒì§€í•©ë‹ˆë‹¤.

### ë°ì´í„°ì…‹
- **í´ë˜ìŠ¤(13ì¢…)**  
  `air_conditioner, chair, desk, drum, microphone, mirror, monitor, piano, projector, speaker, spotlight, stage, whiteboard`
- **êµ¬ì¶•**: ì¥ì†Œ ë°ì´í„°ì—ì„œ **ìë™ ë°•ìŠ¤ ë¼ë²¨ë§** íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì´ˆì•ˆ ìƒì„± â†’ **ìˆ˜ì‘ì—… ë³´ì •**  
- **í˜•ì‹**: YOLO í˜•ì‹ (`images/`, `labels/*.txt` ; ê° txt: `cls cx cy w h`)

```text
ë¼ë²¨ í†µê³„ (íˆìŠ¤í† ê·¸ë¨)
[dataset_trainval]
  0 air_conditioner : 1026   7 piano       : 1265
  1 chair           : 2058   8 projector   : 1026
  2 desk            : 4199   9 speaker     : 1900
  3 drum            : 3444  10 spotlight   : 6136
  4 microphone      : 1126  11 stage       : 1012
  5 mirror          : 1185  12 whiteboard  : 1504
  6 monitor         : 1391

[dataset_test]
  0 air_conditioner :   7   7 piano       :  22
  1 chair           :  94   8 projector   :  10
  2 desk            :  69   9 speaker     :  22
  3 drum            :  13  10 spotlight   : 142
  4 microphone      :  15  11 stage       :   8
  5 mirror          :  44  12 whiteboard  :  13
  6 monitor         :  14
```

**YOLO ë°ì´í„° ì„¤ì • ì˜ˆì‹œ(`space.yaml`)**
```yaml
path: ./space_data
train: images/train
val: images/val
test: images/test
names:
  0: air_conditioner
  1: chair
  2: desk
  3: drum
  4: microphone
  5: mirror
  6: monitor
  7: piano
  8: projector
  9: speaker
 10: spotlight
 11: stage
 12: whiteboard
```

**í•™ìŠµ/í‰ê°€/ì¶”ë¡ **
```python
from ultralytics import YOLO
model = YOLO("yolov8n.pt")
model.train(data="space_data/space.yaml", imgsz=640, epochs=80, batch=16, seed=42)
model.val(data="space_data/space.yaml", imgsz=640, split="val")
model.predict(source="space_data/images/test", imgsz=640, conf=0.25, save=True)
```

**ì„±ëŠ¥ ìš”ì•½**  
- 80 epochs ì™„ë£Œ, best/last ê°€ì¤‘ì¹˜ ì €ì¥ (`runs/detect/space_no_leak/weights/best.pt`)  
- **Val**: `mAP50=0.981`, `mAP50-95=0.912`  
- **Test**: `mAP50=0.979`, `mAP50-95=0.910`

| Split | mAP@0.5 | mAP@0.5:0.95 | ImgSize | Model  |
|---:|---:|---:|---:|---|
| Val | **0.981** | **0.912** | 640 | YOLOv8n |
| Test | **0.979** | **0.910** | 640 | YOLOv8n |

> Speed(ref): ~0.3ms preprocess, 5.0ms inference, 3.2ms postprocess / image (T4)


**ì„±ëŠ¥ í‰ê°€ ì‹œê°í™”**

<img width="567" height="455" alt="item detection" src="https://github.com/user-attachments/assets/e248f3d1-f9a8-4431-aa70-1dc5cbf5f412" />
<img width="567" height="455" alt="itemdetection2" src="https://github.com/user-attachments/assets/128888fa-e291-4220-86f1-c5009b8bdff4" />
<img width="1189" height="390" alt="itemdetection3" src="https://github.com/user-attachments/assets/080dad08-3f4d-4199-b986-8208990ef76c" />



---

## C) Change Detection (ì „í›„ ë³€í™” ê°ì§€)

**ëª¨ë¸**: TinyChangeUNet *(MobileNetV3 Small encoder + TinyDecoder)*  
**ì…ë ¥**: `before(3) + after(3) + diff(1)` = **7ì±„ë„** (`diff = mean(|before - after|)`)

### ë°ì´í„°ì…‹ êµ¬ì¶• (Before/After + GT ë§ˆìŠ¤í¬)

**ëª©í‘œ**
1. ì‹¤ì œ í™˜ê²½ê³¼ ìœ ì‚¬í•œ **ë‹¤ì–‘í•œ ë³€í™”(ê°€ë¦¼/ë¸”ëŸ¬/í”½ì…€í™”/ì¸í˜ì¸íŠ¸/ì´ë™)** ë¥¼ ìë™ ì ìš©í•´ `(before, after, mask)` ìŒ ì¼ê´„ ìƒì„±  
2. **ë§ˆìŠ¤í¬ ê·œì¹™**: `0=ë°°ê²½`, `255=ë³€ê²½ ì˜ì—­`  
3. **í™œìš©**: ë³€í™” ê°ì§€, ì „/í›„ ë¹„êµ, **ë¶„í• (Segmentation)** í•™ìŠµ/ë²¤ì¹˜ë§ˆí‚¹

**ìƒì„± ë¡œì§ ìš”ì•½**
- YOLO ë¼ë²¨ ë°•ìŠ¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì˜ì—­ ì„ íƒ í›„, ì•„ë˜ ì¤‘ í•˜ë‚˜ ì ìš©  
  `black / rect(noise) / blur / pixelate / inpaint / move(ì˜ì—­ ì´ë™)`  
- ë°•ìŠ¤ **jitter/ì—¬ìœ **ì™€ **ë¶€ë¶„ ê°€ë¦¼**ìœ¼ë¡œ ë‚œì´ë„ ë‹¤ì–‘í™”  
- ê²°ê³¼: `before_images/`(ì›ë³¸), `after_images/`(ë³€í˜•), `labels/`(0/255 PNG ë§ˆìŠ¤í¬)
  
**ìƒì„± ë°ì´í„° ì˜ˆì‹œ**
<img width="950" height="247" alt="change3" src="https://github.com/user-attachments/assets/fad3c96a-25fa-48f9-b470-d265750a26c5" />
<img width="950" height="196" alt="change4" src="https://github.com/user-attachments/assets/89c8297f-7ae5-46b0-867f-8c434cff6406" />
<img width="950" height="247" alt="change5" src="https://github.com/user-attachments/assets/cf163ec4-030f-4f0f-84b7-bb3f17741960" />
<img width="950" height="247" alt="change6" src="https://github.com/user-attachments/assets/5a86a376-045f-4b66-b920-d8ab19ac50c9" />


**ëª¨ë¸ êµ¬ì¡° ìš”ì•½**
- `concat([before, after, diff]) â†’ 1Ã—1 conv`ë¡œ **7ch â†’ 3ch ì¶•ì†Œ**  
- **Encoder**: `MobileNetV3 Small (timm, features_only)` â†’ ì±„ë„ ì •ê·œí™”(24/40/64/96)  
- **Decoder(TinyDecoder)**: `ConvTranspose2d` ì—…ìƒ˜í”Œ + ìŠ¤í‚µ + `DWConvBlock`  
- **Head**: `1Ã—1 conv â†’ logit(1ch)` â†’ bilinear ì—…ìƒ˜í”Œ(ì›í•´ìƒë„)

**í•™ìŠµ/í‰ê°€ (change_detection.ipynb)**
- ê¸°ë³¸: `IMG_SIZE=256`, `BATCH=8`, `EPOCHS=40`, `LR=3e-4`  
- ë£¨í”„: AMP(FP16), **Cosine+Warmup(2ep)**, **EMA(0.99)**, gradient clip  
- ì†ì‹¤: `BCEWithLogits(pos_weight)` + `Tversky(Î±=0.7, Î²=0.3)`  
- ê²€ì¦ **threshold sweep**: `th âˆˆ [0.02, 0.40]`ì—ì„œ **F1 ìµœëŒ€**ë¥¼ ì„ íƒ

**ì„±ëŠ¥ ìš”ì•½ (Val ë¡œê·¸ ê¸°ë°˜)**  
- Early stop(F1), ì´ Epoch **39**  
- **Best F1(EMA)**: **0.510 @ th=0.36**  
- ë§ˆì§€ë§‰ Epoch(38): `train loss=0.4530`, `val loss=0.6248`, `mIoU=0.413`, `F1=0.513`
<img width="700" height="400" alt="018df41c-b2a7-4fce-857b-5fb91b2bce7a" src="https://github.com/user-attachments/assets/423cec67-b84f-4cb0-8440-bc16c06121ee" />


**test ì˜ˆì‹œ ì‚¬ì§„**
<img width="1189" height="327" alt="chang" src="https://github.com/user-attachments/assets/11f73c91-58ab-4f07-bbb9-8710c0a4ef7b" />

| Split | Best-th | mIoU | F1 | AMP | EMA |
|---:|---:|---:|---:|:--:|:--:|
| Val | **0.36** | **0.413** | **0.513** | âœ… | âœ… |

<!-- ì„ íƒ: ì˜ˆì¸¡ ë§ˆìŠ¤í¬ ì‹œê°í™” ìœ í‹¸
```python
def overlay(rgb, mask, color=(0,255,255), alpha=0.35):
    import numpy as np
    m = (mask > 127).astype(np.uint8)
    tint = np.ones_like(rgb, dtype=np.uint8) * np.array(color, dtype=np.uint8)
    over = (rgb*(1-alpha) + tint*alpha).astype(np.uint8)
    out = rgb.copy(); out[m>0] = over[m>0]
    return out
```
-->

---

## ğŸ” ì¬í˜„ì„±
- ê³µí†µ ì‹œë“œ: `42` (ìŠ¤í”Œë¦¿ ëˆ„ìˆ˜ ë°©ì§€, ë¡œê·¸/ì²´í¬í¬ì¸íŠ¸ ê³ ì •)  
- ê²€ì¦/ì €ì¥: **EMA ê°€ì¤‘ì¹˜** ê¸°ì¤€  
